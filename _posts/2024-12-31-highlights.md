# Celebrating Our Achievements in 2024: A Year of Innovation, Collaboration, and Growth

As 2024 comes to an end, we’re taking a moment to reflect on the remarkable journey our research team has undertaken over the past twelve months. The excitement, curiosity, and commitment to pushing boundaries have defined our work this year. Here’s a look at some of the highlights that made 2024 extraordinary.

With language generation models being more powerful than ever, we successfully started exploring numerous cross-disciplinary areas:

**LLMs and Human Behavior:** With LLMs producing seemingly natural conversations, we wonder how exactly their skills differ from their human counterparts, and where they can complement and learn from each other. How do LLMs impact collaboration? How well can they reason about their choices? And what does it mean for LLMs to exhibit social skills or to master the creative art of storytelling?
Our multi-institutional [paper on collective intelligence](https://www.nature.com/articles/s41562-024-01959-9.epdf?sharing_token=erCX1S8WW_F8eDmzVJhBLdRgN0jAjWel9jnR3ZoTv0O7cynlnT-2JDsSZ_qJnEFR8B0Lqw0K8nJC4iPaGVHQDhU--UDrDIuPZrf3buif_0GuQFKp5cgeb3Rd4ddl67xcOwcv-NndaRT8rdjFRy_BdYd8rD-x7TrglCtBGSCUADE%3D) was published in Nature Human Behavior and was covered by numerous media such as [Forbes](https://www.forbes.com/sites/lanceeliot/2024/11/18/ai-is-now-co-creator-of-our-collective-intelligence-so-watch-your-back/). Our ACL [Workshop on Human-Centered LLMs](https://aclanthology.org/volumes/2024.hucllm-1/) had over 200 in person attendees in Bangkok. 
At ACL we have shown how [LLMs can improve in taking the perspective of others](https://aclanthology.org/2024.findings-acl.387/) by learning to generate responses to conflict situations. In our [awarded poster](https://x.com/lucie_nlp/status/1858828683554787503) at EMNLP WiNLP in Miami, we explained that to-date LLMs are by far not yet robust in reasoning about the behavior of others. At [NeurIPS Workshop on System 2 Reasoning](https://s2r-at-scale-workshop.github.io/) we have demonstrated how [telling better stories ](https://lamarr-institute.org/blog/sot-llm-reasoning/)in explanations can improve LLM accuracy in scientific question answering. Narratives also play a key role in our [Bonn-Melbourne Research Excellence Grant](https://www.linkedin.com/posts/flekova_new-misinformationframingnarrative-research-activity-7265646828870590466-W_MP?utm_source=share&utm_medium=member_desktop) on understanding indoctrination mechanisms at scale. 

**LLMs for Mental Health:** What is the potential of LLMs for mental health screening? And for treatment? With our psychology colleagues from Stony Brook University, Stanford and Lund, [we found ](https://arxiv.org/abs/2411.13800)that GPT-4’s assessment and explanation of depression severity had high overall convergent validity (r = 0.81 with experts) and internal model consistency that largely aligned with literature and item-level self-assessment via well-established questionnaires. Such pre-screening may allow clinicians to invest more time into carefully tailored treatment plans. 
In the [InVirtuo collaboration](https://invirtuo.org/), we explore the development of empathetic, socially competent personalized LLMs to empower virtual reality avatars in behavioral therapy.

**LLMs and Physics:** LLMs are merely powerful pretrained models for finding complex patterns in long time series. What if we apply these to particle physics and astrophysics? Whether searching for high-frequency gravitational waves ([TRA Matter / GravNet](https://www.pi.uni-bonn.de/gravnet/en)), analyzing AGN light curves ([Lamarr Physics](https://lamarr-institute.org/research/physics/)), investigating the adversarial robustness of particle physics models ([ErUM-Data AI Safety](https://www.b-it-center.de/caisa/research/entwicklung-von-methoden-zur-abschaetzung-der-sicherheit-von-vorhersagen-neuronaler-netzwerke-und-verbesserung-ihrer-robustheit-aisafety)), or searching for new galaxy clusters with AstroLlama and multimodal representation learning ([DynaVerse](https://dynaverse.astro.uni-koeln.de/our-team)), we are excited what our new projects may reveal!

**LLMs and Biomedicine:** Can LLMs accelerate research by harmonizing scientific literature? With our new seed funding from TRA Modelling, we use [LLMs to detect patterns in gene regulation dysfunctions](https://www.b-it-center.de/news-details/decoding-cancer-how-large-language-models-could-change-gene-regulation-research) associated with cancer, reconstructing gene regulatory networks from published experimental findings.

Within [**Lamarr NLP**](https://lamarr-institute.org/research/natural-language-processing/), we have established a strong collaboration on LLM research with the Fraunhofer IAIS teams on Foundation Models and Trustworthy AI (joint [paper](https://aclanthology.org/2024.c3nlp-1.6/) on multilingual alignment), as well as with TU Dortmund on Sustainable AI (joint [paper](https://arxiv.org/abs/2408.14398v3) on LLM pruning). With the newly released Teuken-7B model, we are excited about more joint open-source multilingual LLM research to come.

With 2024 being the[ USA-NRW year](https://nrw-usa.nrw/en/about-the-nrw-usa-year), we celebrated our partnerships by organizing a [Lamarr AI Event](https://nathalieschueller.smugmug.com/Official-Events-2024/UA-Ruhr-Event-April-8-2024/n-3xj96H) at the German Consulate General in NYC, marking a start of numerous PhD visits. Apart from our traditionally strong collaborations with Stony Brook, NYU, CMU, UPenn and UMich, we are happy about our reinforced ties to Stanford University, where Prof. Flek recently presented our perspectivism work. In 2024 we organized a joint [LLM workshop](https://hucllm-workshop.github.io/#Schedule) (Diyi Yang),  authored a joint [mental health paper](https://arxiv.org/abs/2411.13800) (Johannes Eichstadt, Betsy Stade), founded the IMPULSE House for Intellectual Innovation and Creativity in Bonn (Sepp Gumbrecht), and Oussama Khatib from the [b-it ](https://www.b-it-center.de/news-details/meeting-ai-experts-in-the-usa-prof-dr-lucie-flek-on-delegation-trip)advisory board has welcomed [our](https://www.informatik.uni-bonn.de/en/news/our-news-reports/flek-delegation-trip-usa) [NRW delegation ](https://www.land.nrw/pressemitteilung/ministerpraesident-wuest-im-silicon-valley-wir-brauchen-eine-werte-allianz-fuer)in his Stanford robotics lab.

In numbers, our team has hired 7 new FTEs (including a new junior research group on LLM agents), published 17 peer-reviewed papers, organized 4 LLM workshops, gave many talks across three continents, acquired four new grants, joined 10 PhD committees in 4 countries, and hosted 4 visiting research fellows and 10 invited speakers from all over the world (UPenn, EPFL, RMIT, Monash, UMich, NYU, SBU, Sheffield, Edinburgh, UPV). One team member accepted a professorship offer and two completed their PhD, all continuing their work in the field (Canada, US, Germany). Also with junior researchers we are off to a great start. We supervised over 20 master theses, many of which were published in international workshops; two students received a best poster award at a top US conference. Last but not least, the first two caisarians are now mothers of beautiful babies. 

While 2024 was a great year, it’s only the beginning of our journey. As we enter 2025, we carry forward the momentum generated by our research projects and collaborations. 

To our dedicated researchers, collaborators, and supporters: thank you for your unwavering commitment to pushing the boundaries of human knowledge. Here's to another year of curiosity, innovation, and transformative research!


